{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model\n",
    "\n",
    "Long Short Term Memory is implemented using keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading preprocessed train data\n",
    "\n",
    "train = pd.read_csv('train_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the text data\n",
    "\n",
    "Machine learning algorithms cannot understand raw text, so we convert the text into tokens of numbers or vectors for the machine to work upon. Keras implemented tokenizer is used here for the same with max_words = 5000 and maxlen for padding the sequence = 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,  791, 1461],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 301, 2687,   15, ...,   15,  301, 2687],\n",
       "       [4845,   39,  130, ...,   39,  130, 1950],\n",
       "       [   8,  562, 1462, ...,   99,    6,  584]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, lower=True)\n",
    "tokenizer.fit_on_texts(train['comment_text'].values.astype('U'))\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(train['comment_text'].values.astype('U'))\n",
    "\n",
    "# max length for each comment = 200\n",
    "x = pad_sequences(sequences, maxlen=200)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, 0, 1, 1],\n",
       "       [1, 0, 0, 0, 1, 0],\n",
       "       [1, 1, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting label values to array\n",
    "\n",
    "Y=[]\n",
    "Y=pd.DataFrame(Y)\n",
    "\n",
    "Y['toxic']=train['toxic']\n",
    "Y['severe_toxic']=train['severe_toxic']\n",
    "Y['obscene']=train['obscene']\n",
    "Y['threat']=train['threat']\n",
    "Y['insult']=train['insult']\n",
    "Y['identity_hate']=train['identity_hate']\n",
    "\n",
    "y=Y.values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data with test_size=0.2\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer using GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an embedding matrix \n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "\n",
    "glove_file = open('glove.6B.200d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "embedding_matrix = zeros((vocab_size, 200))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Network.summary of <keras.engine.training.Model object at 0x0000018DC0F9EDD8>>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input layer\n",
    "deep_inputs = Input(shape=(200,))  \n",
    "\n",
    "# embedding layer\n",
    "embedding_layer = Embedding(vocab_size, 200, weights=[embedding_matrix], trainable=False)(deep_inputs)\n",
    "\n",
    "# LSTM layer \n",
    "LSTM_Layer = LSTM(128)(embedding_layer)\n",
    "\n",
    "# number of classes (labels)\n",
    "n_classes = 6\n",
    "\n",
    "# Dense output layer with activation function \n",
    "dense_layer = Dense(n_classes, activation='sigmoid')(LSTM_Layer)\n",
    "\n",
    "# adding inputs and outputs to Model\n",
    "model = Model(inputs=deep_inputs, outputs=dense_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# defining callbacks\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4)\n",
    "]\n",
    "\n",
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114890 samples, validate on 12766 samples\n",
      "Epoch 1/5\n",
      "114890/114890 [==============================] - 996s 9ms/step - loss: 0.0878 - acc: 0.9725 - val_loss: 0.0755 - val_acc: 0.9755\n",
      "Epoch 2/5\n",
      "114890/114890 [==============================] - 996s 9ms/step - loss: 0.0714 - acc: 0.9766 - val_loss: 0.0692 - val_acc: 0.9776\n",
      "Epoch 3/5\n",
      "114890/114890 [==============================] - 1000s 9ms/step - loss: 0.0667 - acc: 0.9776 - val_loss: 0.0683 - val_acc: 0.9782\n",
      "Epoch 4/5\n",
      "114890/114890 [==============================] - 999s 9ms/step - loss: 0.0637 - acc: 0.9784 - val_loss: 0.0664 - val_acc: 0.9787\n",
      "Epoch 5/5\n",
      "114890/114890 [==============================] - 1000s 9ms/step - loss: 0.0612 - acc: 0.9790 - val_loss: 0.0664 - val_acc: 0.9785\n"
     ]
    }
   ],
   "source": [
    "# fitting data on model\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31915/31915 [==============================] - 94s 3ms/step\n",
      "loss: 0.06696725681000427\n",
      "acc: 0.97788405418396\n"
     ]
    }
   ],
   "source": [
    "# evaluating on test data\n",
    "\n",
    "metrics = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of the model is found to be 97.788 %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on final test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>yo btch ja rule ucceful hall ever what hatng a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>from rfc  ttle fne mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>ource zawe ahton lapland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>f look back ource nformaton  updated correct f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>anonymouly edt artcle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  00001cee341fdb12   \n",
       "1           1  0000247867823ef7   \n",
       "2           2  00013b17ad220c46   \n",
       "3           3  00017563c3f7919a   \n",
       "4           4  00017695ad8997eb   \n",
       "\n",
       "                                        comment_text  \n",
       "0  yo btch ja rule ucceful hall ever what hatng a...  \n",
       "1                             from rfc  ttle fne mo   \n",
       "2                           ource zawe ahton lapland  \n",
       "3  f look back ource nformaton  updated correct f...  \n",
       "4                             anonymouly edt artcle   "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_preprocessed.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   67,  406,   23],\n",
       "       [   0,    0,    0, ...,  227,  585, 1138],\n",
       "       [   0,    0,    0, ...,    0,    0,   18],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   71,  376, 1481],\n",
       "       [   0,    0,    0, ...,   95,   32, 3030],\n",
       "       [   0,    0,    0, ...,   42, 4407,    6]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting into tokens using the already fitted tokenizer\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(test['comment_text'].values.astype('U'))\n",
    "test = pad_sequences(sequences, maxlen=200)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.8824431e-01, 2.4684701e-02, 2.7665856e-01, 8.8207629e-03,\n",
       "        3.5306579e-01, 1.2820670e-02],\n",
       "       [1.0223834e-02, 7.2372604e-05, 2.1600914e-03, 6.0475661e-05,\n",
       "        1.6437232e-03, 4.4416077e-04],\n",
       "       [1.0051875e-01, 8.6456407e-03, 4.7148466e-02, 3.4774127e-03,\n",
       "        3.6964547e-02, 1.1818649e-02],\n",
       "       ...,\n",
       "       [3.2930311e-03, 9.3068711e-06, 8.9360651e-04, 1.2402681e-05,\n",
       "        3.5051693e-04, 1.0660733e-04],\n",
       "       [1.0797491e-02, 6.0468625e-05, 2.6358413e-03, 2.9793109e-05,\n",
       "        1.4728478e-03, 1.1371445e-03],\n",
       "       [7.5652689e-01, 8.5971421e-03, 1.8018711e-01, 5.7314313e-03,\n",
       "        3.2273018e-01, 8.7631727e-03]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making predictions\n",
    "\n",
    "predictions = model.predict(test, batch_size = 32)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12    0.5           0.5      0.5     0.5     0.5   \n",
       "1  0000247867823ef7    0.5           0.5      0.5     0.5     0.5   \n",
       "2  00013b17ad220c46    0.5           0.5      0.5     0.5     0.5   \n",
       "3  00017563c3f7919a    0.5           0.5      0.5     0.5     0.5   \n",
       "4  00017695ad8997eb    0.5           0.5      0.5     0.5     0.5   \n",
       "\n",
       "   identity_hate  \n",
       "0            0.5  \n",
       "1            0.5  \n",
       "2            0.5  \n",
       "3            0.5  \n",
       "4            0.5  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submitting on the file\n",
    "\n",
    "submissions = pd.read_csv('sample_submission.csv')\n",
    "submissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.788244</td>\n",
       "      <td>0.024685</td>\n",
       "      <td>0.276659</td>\n",
       "      <td>0.008821</td>\n",
       "      <td>0.353066</td>\n",
       "      <td>0.012821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.010224</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.100519</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.047148</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.036965</td>\n",
       "      <td>0.011819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.073786</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.788244      0.024685  0.276659  0.008821  0.353066   \n",
       "1  0000247867823ef7  0.010224      0.000072  0.002160  0.000060  0.001644   \n",
       "2  00013b17ad220c46  0.100519      0.008646  0.047148  0.003477  0.036965   \n",
       "3  00017563c3f7919a  0.000312      0.000003  0.000165  0.000013  0.000063   \n",
       "4  00017695ad8997eb  0.073786      0.002617  0.034611  0.003516  0.036050   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.012821  \n",
       "1       0.000444  \n",
       "2       0.011819  \n",
       "3       0.000022  \n",
       "4       0.001155  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions['toxic'] = predictions[:,0]\n",
    "submissions['severe_toxic'] = predictions[:,1]\n",
    "submissions['obscene'] = predictions[:,2]\n",
    "submissions['threat'] = predictions[:,3]\n",
    "submissions['insult'] = predictions[:,4]\n",
    "submissions['identity_hate'] = predictions[:,5]\n",
    "\n",
    "submissions.to_csv('submission_lstm.csv')\n",
    "submissions.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
