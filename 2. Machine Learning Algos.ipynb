{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying machine learning models \n",
    "\n",
    "Deployed 2 machine learning algorithms- Logistic Regression and Naive Bayes and compared them on the basis of accuracy and f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading preprocessed train and test data\n",
    "\n",
    "train = pd.read_csv('train_preprocessed.csv')\n",
    "test = pd.read_csv('test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0           0             0        0       0       0              0\n",
       "1           0             0        0       0       0              0\n",
       "2           0             0        0       0       0              0\n",
       "3           1             0        1       0       1              0\n",
       "4           1             1        1       0       1              0\n",
       "...       ...           ...      ...     ...     ...            ...\n",
       "159566      1             1        1       0       1              1\n",
       "159567      1             0        0       0       0              0\n",
       "159568      1             0        0       0       1              1\n",
       "159569      1             0        0       0       1              0\n",
       "159570      1             1        0       1       0              0\n",
       "\n",
       "[159571 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing x and y for fitting into model\n",
    "\n",
    "x = train['comment_text'].values.astype('U')\n",
    "          \n",
    "y = []\n",
    "y = pd.DataFrame(y)\n",
    "          \n",
    "y['toxic'] = train['toxic']\n",
    "y['severe_toxic'] = train['severe_toxic']\n",
    "y['obscene'] = train['obscene']\n",
    "y['threat'] = train['threat']\n",
    "y['insult'] = train['insult']\n",
    "y['identity_hate'] = train['identity_hate']\n",
    "          \n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the text data using TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning algorithms cannot work on the raw text directly. So, feature extraction is used to convert the text into a matrix of vectors of features. \n",
    "I have used TF-IDF(term frequency-inverse document frequency) for the same on the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=5000,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(max_features=5000,stop_words='english')\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 233)\n",
    "\n",
    "# fitting the vectorizer in train and test text data\n",
    "x_vec = vec.fit_transform(X_train)\n",
    "x_vec_test = vec.transform(X_test)\n",
    "\n",
    "# fitting in the final test data\n",
    "test = vec.transform(test['comment_text'].values.astype('U'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining labels in a list\n",
    "labels = y.columns\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Logistic Regression model\n",
    "Tried on differnt values of C = 1.0, 3.0, 5.0, 12.0, took that gave the best accuracy and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticreg(X_train, X_test, y_train, y_test, test):\n",
    "    \n",
    "    logreg = LogisticRegression(C=3.0, max_iter=1000) \n",
    "        \n",
    "    logreg.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = logreg.predict(X_test)\n",
    "    \n",
    "    model_logreg.append(logreg.predict_proba(test)[:,1]) #predicting probability for final test data\n",
    "    \n",
    "    return accuracy_score(y_test,y_pred), f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For label: toxic\n",
      "Accuracy- 0.9574808083973053\n",
      "F1-score- 0.7464972912385578\n",
      "\n",
      "\n",
      "For label: severe_toxic\n",
      "Accuracy- 0.9899733667554441\n",
      "F1-score- 0.3725490196078432\n",
      "\n",
      "\n",
      "For label: obscene\n",
      "Accuracy- 0.9783487388375373\n",
      "F1-score- 0.7709645343056016\n",
      "\n",
      "\n",
      "For label: threat\n",
      "Accuracy- 0.9971486761710794\n",
      "F1-score- 0.2352941176470588\n",
      "\n",
      "\n",
      "For label: insult\n",
      "Accuracy- 0.9712047626507911\n",
      "F1-score- 0.6639853747714808\n",
      "\n",
      "\n",
      "For label: identity_hate\n",
      "Accuracy- 0.9922920256932477\n",
      "F1-score- 0.3910891089108911\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_logreg = []  #list for containing probability of labels on test data.\n",
    "\n",
    "for i in range(0,6) :\n",
    "    \n",
    "    print(\"For label:\",labels[i])\n",
    "    \n",
    "    acc, f1 = logisticreg(x_vec, x_vec_test, y_train[labels[i]], y_test[labels[i]], test)\n",
    " \n",
    "    print(\"Accuracy-\",acc)\n",
    "    print(\"F1-score-\",f1)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.99749107, 0.00379326, 0.01144098, ..., 0.00295491, 0.01399935,\n",
       "        0.99228101]),\n",
       " array([0.13117531, 0.00175925, 0.00112061, ..., 0.00088052, 0.00223239,\n",
       "        0.00172593]),\n",
       " array([0.99797392, 0.0014692 , 0.00174237, ..., 0.00438719, 0.01677793,\n",
       "        0.94202003]),\n",
       " array([0.06389543, 0.00046256, 0.00012203, ..., 0.00058336, 0.00222849,\n",
       "        0.0034816 ]),\n",
       " array([0.95462112, 0.00871706, 0.0022137 , ..., 0.00211739, 0.02075944,\n",
       "        0.55966147]),\n",
       " array([0.25381916, 0.00226104, 0.00033727, ..., 0.00025751, 0.0271829 ,\n",
       "        0.00769689])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted probabilities of each label of every comment of naive bayes model\n",
    "\n",
    "model_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12    0.5           0.5      0.5     0.5     0.5   \n",
       "1  0000247867823ef7    0.5           0.5      0.5     0.5     0.5   \n",
       "2  00013b17ad220c46    0.5           0.5      0.5     0.5     0.5   \n",
       "3  00017563c3f7919a    0.5           0.5      0.5     0.5     0.5   \n",
       "4  00017695ad8997eb    0.5           0.5      0.5     0.5     0.5   \n",
       "\n",
       "   identity_hate  \n",
       "0            0.5  \n",
       "1            0.5  \n",
       "2            0.5  \n",
       "3            0.5  \n",
       "4            0.5  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submitting the predicted probabilities of logistic regression model\n",
    "\n",
    "submission_logreg = pd.read_csv('sample_submission.csv')\n",
    "submission_logreg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.997491</td>\n",
       "      <td>0.131175</td>\n",
       "      <td>0.997974</td>\n",
       "      <td>0.063895</td>\n",
       "      <td>0.954621</td>\n",
       "      <td>0.253819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>0.002261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.011441</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.012713</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.997491      0.131175  0.997974  0.063895  0.954621   \n",
       "1  0000247867823ef7  0.003793      0.001759  0.001469  0.000463  0.008717   \n",
       "2  00013b17ad220c46  0.011441      0.001121  0.001742  0.000122  0.002214   \n",
       "3  00017563c3f7919a  0.002199      0.001210  0.001913  0.000207  0.002106   \n",
       "4  00017695ad8997eb  0.012713      0.000351  0.002811  0.000617  0.003881   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.253819  \n",
       "1       0.002261  \n",
       "2       0.000337  \n",
       "3       0.000229  \n",
       "4       0.000298  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_logreg['toxic'] = model_logreg[0]\n",
    "submission_logreg['severe_toxic'] = model_logreg[1]\n",
    "submission_logreg['obscene'] = model_logreg[2]\n",
    "submission_logreg['threat'] = model_logreg[3]\n",
    "submission_logreg['insult'] = model_logreg[4]\n",
    "submission_logreg['identity_hate'] = model_logreg[5]\n",
    "\n",
    "submission_logreg.to_csv('submission_logreg.csv')  # saving the submissions\n",
    "submission_logreg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_classifier(X_train, X_test, y_train, y_test, test):\n",
    "  \n",
    "    nb = MultinomialNB(alpha = 1.0)\n",
    "    \n",
    "    nb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = nb.predict(X_test)\n",
    "    \n",
    "    model_nb.append(nb.predict_proba(test)[:,1]) #predicting probability for final test data\n",
    "\n",
    "    return accuracy_score(y_test,y_pred), f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For label- toxic\n",
      "Accuracy- 0.9493968353438822\n",
      "F1-score- 0.657476139978791\n",
      "\n",
      "\n",
      "For label- severe_toxic\n",
      "Accuracy- 0.9896287012376626\n",
      "F1-score- 0.19854721549636806\n",
      "\n",
      "\n",
      "For label- obscene\n",
      "Accuracy- 0.9723014256619145\n",
      "F1-score- 0.6733185513673318\n",
      "\n",
      "\n",
      "For label- threat\n",
      "Accuracy- 0.996960676797744\n",
      "F1-score- 0.0\n",
      "\n",
      "\n",
      "For label- insult\n",
      "Accuracy- 0.9675387748707505\n",
      "F1-score- 0.5785191212367778\n",
      "\n",
      "\n",
      "For label- identity_hate\n",
      "Accuracy- 0.991540028199906\n",
      "F1-score- 0.1176470588235294\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_nb = []   #saving models of each label in a list for further use\n",
    "\n",
    "for l in range(0,6) :\n",
    "    print(\"For label-\",labels[l])\n",
    "    \n",
    "    acc, f1 = nb_classifier(x_vec, x_vec_test, y_train[labels[l]], y_test[labels[l]], test)\n",
    "  \n",
    "    print(\"Accuracy-\",acc)\n",
    "    print(\"F1-score-\",f1)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.98545498, 0.01653995, 0.03079137, ..., 0.0067458 , 0.03861701,\n",
       "        0.64189787]),\n",
       " array([0.15070855, 0.00145118, 0.00095912, ..., 0.00146327, 0.00307092,\n",
       "        0.00696372]),\n",
       " array([0.96109403, 0.00778984, 0.01273684, ..., 0.00339215, 0.01858582,\n",
       "        0.3296341 ]),\n",
       " array([0.0059854 , 0.00040092, 0.00014569, ..., 0.00087884, 0.0024659 ,\n",
       "        0.00318041]),\n",
       " array([0.92439506, 0.00963679, 0.01034718, ..., 0.00312236, 0.02029692,\n",
       "        0.25974141]),\n",
       " array([0.1367684 , 0.00169943, 0.00080837, ..., 0.00143969, 0.02067246,\n",
       "        0.01107733])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted probabilities of each label of every comment of naive bayes model\n",
    "model_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12    0.5           0.5      0.5     0.5     0.5   \n",
       "1  0000247867823ef7    0.5           0.5      0.5     0.5     0.5   \n",
       "2  00013b17ad220c46    0.5           0.5      0.5     0.5     0.5   \n",
       "3  00017563c3f7919a    0.5           0.5      0.5     0.5     0.5   \n",
       "4  00017695ad8997eb    0.5           0.5      0.5     0.5     0.5   \n",
       "\n",
       "   identity_hate  \n",
       "0            0.5  \n",
       "1            0.5  \n",
       "2            0.5  \n",
       "3            0.5  \n",
       "4            0.5  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submitting the predicted probabilities of logistic regression model\n",
    "\n",
    "submission_nb = pd.read_csv('sample_submission.csv')\n",
    "submission_nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.150709</td>\n",
       "      <td>0.961094</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.924395</td>\n",
       "      <td>0.136768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.016540</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>0.001699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.030791</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.012737</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.010347</td>\n",
       "      <td>0.000808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.006820</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.039287</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.985455      0.150709  0.961094  0.005985  0.924395   \n",
       "1  0000247867823ef7  0.016540      0.001451  0.007790  0.000401  0.009637   \n",
       "2  00013b17ad220c46  0.030791      0.000959  0.012737  0.000146  0.010347   \n",
       "3  00017563c3f7919a  0.006820      0.000271  0.003074  0.000045  0.002883   \n",
       "4  00017695ad8997eb  0.039287      0.000608  0.016786  0.000129  0.013979   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.136768  \n",
       "1       0.001699  \n",
       "2       0.000808  \n",
       "3       0.000180  \n",
       "4       0.000550  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_nb['toxic'] = model_nb[0]\n",
    "submission_nb['severe_toxic'] = model_nb[1]\n",
    "submission_nb['obscene'] = model_nb[2]\n",
    "submission_nb['threat'] = model_nb[3]\n",
    "submission_nb['insult'] = model_nb[4]\n",
    "submission_nb['identity_hate'] = model_nb[5]\n",
    "\n",
    "submission_nb.to_csv('submission_nb.csv')    # saving the submissions\n",
    "submission_nb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On comapring Logistic Regression model and Naive Bayes model on the basis of accuracy and f1-score, we observe that Logistic Regression outperformed with better accuracy as well as f1-score for each label. \n",
    "\n",
    "Although labels sever_toxic, threat and identity_hate have high accuracy but they have low f1-score (< 0.5) which indicates that models for these labels does not perform good on False Negatives or False Positives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
